{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "white_wine=pd.read_csv('../../practice/winequality-white.csv', sep=';')\n",
    "red_wine=pd.read_csv('../../practice/winequality-red.csv', sep=';')\n",
    "white_wine.columns=white_wine.columns.str.replace(' ','_')\n",
    "red_wine.columns=red_wine.columns.str.replace(' ','_')\n",
    "white_wine['wine_type']=0\n",
    "red_wine['wine_type']=1\n",
    "red_wine['wine_type'].astype('int64')\n",
    "total_wine=pd.concat([white_wine, red_wine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_acidity           0\n",
      "volatile_acidity        0\n",
      "citric_acid             0\n",
      "residual_sugar          0\n",
      "chlorides               0\n",
      "free_sulfur_dioxide     0\n",
      "total_sulfur_dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "wine_type               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(total_wine.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed_acidity           float64\n",
       "volatile_acidity        float64\n",
       "citric_acid             float64\n",
       "residual_sugar          float64\n",
       "chlorides               float64\n",
       "free_sulfur_dioxide     float64\n",
       "total_sulfur_dioxide    float64\n",
       "density                 float64\n",
       "pH                      float64\n",
       "sulphates               float64\n",
       "alcohol                 float64\n",
       "quality                   int64\n",
       "wine_type                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_wine.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sI use z score method to remove outliers\n",
    "def outliers_remov(df):\n",
    "    df_out=df.copy()\n",
    "    for colu in total_wine:\n",
    "        per95_df=df[colu].quantile(0.95)\n",
    "        per5_df=df[colu].quantile(0.05)\n",
    "        df_out[colu]=np.where(df[colu] >  per95_df,\n",
    "        per95_df, df[colu])   \n",
    "        df_out[colu]=np.where(df_out[colu] <  per5_df,\n",
    "        per5_df, df_out[colu])       \n",
    "        df=df_out     \n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "total_wine=outliers_remov(total_wine)\n",
    "total_wine= total_wine.set_index(np.arange(len(total_wine)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :\n",
      " 0.9945128205128204 \n",
      "cohen: \n",
      " 0.9852031569717734 \n",
      "confusion \n",
      " [array([[1460,    4],\n",
      "       [   5,  481]]), array([[1485,    3],\n",
      "       [   4,  458]]), array([[1455,    2],\n",
      "       [   6,  487]]), array([[1470,    9],\n",
      "       [   4,  467]]), array([[1478,    7],\n",
      "       [   6,  459]]), array([[1455,    5],\n",
      "       [   7,  483]]), array([[1455,   10],\n",
      "       [   1,  484]]), array([[1454,   10],\n",
      "       [   3,  483]]), array([[1459,    3],\n",
      "       [   8,  480]]), array([[1481,    6],\n",
      "       [   4,  459]])] classification: \n",
      " ['              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1464\\n         1.0       0.99      0.99      0.99       486\\n\\n    accuracy                           1.00      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       1.00      1.00      1.00      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1488\\n         1.0       0.99      0.99      0.99       462\\n\\n    accuracy                           1.00      1950\\n   macro avg       1.00      0.99      1.00      1950\\nweighted avg       1.00      1.00      1.00      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1457\\n         1.0       1.00      0.99      0.99       493\\n\\n    accuracy                           1.00      1950\\n   macro avg       1.00      0.99      0.99      1950\\nweighted avg       1.00      1.00      1.00      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      0.99      1.00      1479\\n         1.0       0.98      0.99      0.99       471\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1485\\n         1.0       0.98      0.99      0.99       465\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1460\\n         1.0       0.99      0.99      0.99       490\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      0.99      1.00      1465\\n         1.0       0.98      1.00      0.99       485\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      1.00      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      0.99      1.00      1464\\n         1.0       0.98      0.99      0.99       486\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1462\\n         1.0       0.99      0.98      0.99       488\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1487\\n         1.0       0.99      0.99      0.99       463\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n']\n",
      "[ 2.22100413  3.59610651 -0.69101231 -2.98271286  4.25929735  0.29897997\n",
      " -6.15516176  5.29529233  2.5441345   2.40886791  2.34356465  0.18493814]\n",
      "Feature:     0, Score: 2.2210\n",
      "Feature:     1, Score: 3.5961\n",
      "Feature:     2, Score: -0.6910\n",
      "Feature:     3, Score: -2.9827\n",
      "Feature:     4, Score: 4.2593\n",
      "Feature:     5, Score: 0.2990\n",
      "Feature:     6, Score: -6.1552\n",
      "Feature:     7, Score: 5.2953\n",
      "Feature:     8, Score: 2.5441\n",
      "Feature:     9, Score: 2.4089\n",
      "Feature:    10, Score: 2.3436\n",
      "Feature:    11, Score: 0.1849\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature importance for LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cohen=[]\n",
    "score=[]\n",
    "confusion=[]\n",
    "class_out=[]\n",
    "for i in range(10): \n",
    "    model=LogisticRegression()\n",
    "    x=total_wine.drop(columns='wine_type')\n",
    "    y=total_wine['wine_type']\n",
    "    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "    scale=MinMaxScaler()\n",
    "    x_train_n= scale.fit_transform(x_train)\n",
    "    x_train_n= pd.DataFrame(x_train_n, columns=x_train.columns)\n",
    "    x_test_n= scale.fit_transform(x_test)\n",
    "    x_test_n= pd.DataFrame(x_test_n, columns=x_test.columns)\n",
    "    model.fit(x_train_n, y_train)\n",
    "    pred=model.predict(x_test_n)\n",
    "    scor=accuracy_score(pred, y_test)\n",
    "    score.append(scor)\n",
    "\n",
    "    con=confusion_matrix(y_test, pred)\n",
    "    confusion.append(con)\n",
    "    class_p= classification_report(y_test,pred)\n",
    "    class_out.append(class_p)\n",
    "    cohe=cohen_kappa_score(y_test, pred)\n",
    "    cohen.append(cohe)\n",
    "    i +=1\n",
    "print('score :\\n', np.mean(score),'\\ncohen: \\n',np.mean(cohen),'\\nconfusion \\n',confusion, 'classification: \\n',class_out)\n",
    "importance = model.coef_[0]\n",
    "print(importance)\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %5d, Score: %0.4f' %(i, v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :\n",
      " 0.9851794871794872 \n",
      "cohen: \n",
      " 0.9597591744541806 \n",
      "confusion \n",
      " [array([[1469,   15],\n",
      "       [   6,  460]]), array([[1453,   20],\n",
      "       [  18,  459]]), array([[1451,   14],\n",
      "       [  13,  472]]), array([[1474,   10],\n",
      "       [  16,  450]]), array([[1462,   17],\n",
      "       [  13,  458]]), array([[1462,   18],\n",
      "       [  13,  457]]), array([[1461,   15],\n",
      "       [  11,  463]]), array([[1446,   16],\n",
      "       [  16,  472]]), array([[1458,    8],\n",
      "       [  20,  464]]), array([[1475,    9],\n",
      "       [  21,  445]])] classification: \n",
      " ['              precision    recall  f1-score   support\\n\\n         0.0       1.00      0.99      0.99      1484\\n         1.0       0.97      0.99      0.98       466\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1473\\n         1.0       0.96      0.96      0.96       477\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.97      0.97      0.97      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1465\\n         1.0       0.97      0.97      0.97       485\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1484\\n         1.0       0.98      0.97      0.97       466\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1479\\n         1.0       0.96      0.97      0.97       471\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1480\\n         1.0       0.96      0.97      0.97       470\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1476\\n         1.0       0.97      0.98      0.97       474\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1462\\n         1.0       0.97      0.97      0.97       488\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1466\\n         1.0       0.98      0.96      0.97       484\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1484\\n         1.0       0.98      0.95      0.97       466\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.97      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n']\n",
      "Feature :     0 , importance 0.00808\n",
      "Feature :     1 , importance 0.05067\n",
      "Feature :     2 , importance 0.00359\n",
      "Feature :     3 , importance 0.00560\n",
      "Feature :     4 , importance 0.21400\n",
      "Feature :     5 , importance 0.00223\n",
      "Feature :     6 , importance 0.66386\n",
      "Feature :     7 , importance 0.02523\n",
      "Feature :     8 , importance 0.00458\n",
      "Feature :     9 , importance 0.01582\n",
      "Feature :    10 , importance 0.00597\n",
      "Feature :    11 , importance 0.00036\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature importance of Decision Tree\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cohen=[]\n",
    "score=[]\n",
    "confusion=[]\n",
    "class_out=[]\n",
    "for i in range(10): \n",
    "    model=DecisionTreeClassifier()\n",
    "    x=total_wine.drop(columns='wine_type')\n",
    "    y=total_wine['wine_type']\n",
    "    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "    scale=MinMaxScaler()\n",
    "    x_train_n= scale.fit_transform(x_train)\n",
    "    x_train_n= pd.DataFrame(x_train_n, columns=x_train.columns)\n",
    "    x_test_n= scale.fit_transform(x_test)\n",
    "    x_test_n= pd.DataFrame(x_test_n, columns=x_test.columns)\n",
    "    model.fit(x_train_n, y_train)\n",
    "    pred=model.predict(x_test_n)\n",
    "    scor=accuracy_score(pred, y_test)\n",
    "    score.append(scor)\n",
    "\n",
    "    con=confusion_matrix(y_test, pred)\n",
    "    confusion.append(con)\n",
    "    class_p= classification_report(y_test,pred)\n",
    "    class_out.append(class_p)\n",
    "    cohe=cohen_kappa_score(y_test, pred)\n",
    "    cohen.append(cohe)\n",
    "    i +=1\n",
    "print('score :\\n', np.mean(score),'\\ncohen: \\n',np.mean(cohen),'\\nconfusion \\n',confusion, 'classification: \\n',class_out)\n",
    "importance=model.feature_importances_\n",
    "for i, v in enumerate(importance):\n",
    "    print('Feature : %5d , importance %0.5f' %(i,v) )\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :\n",
      " 0.9945641025641028 \n",
      "cohen: \n",
      " 0.9852335313477546 \n",
      "confusion \n",
      " [array([[1470,    2],\n",
      "       [  10,  468]]), array([[1468,    1],\n",
      "       [  10,  471]]), array([[1481,    2],\n",
      "       [   5,  462]]), array([[1472,    1],\n",
      "       [  13,  464]]), array([[1478,    1],\n",
      "       [   2,  469]]), array([[1460,    1],\n",
      "       [  15,  474]]), array([[1464,    4],\n",
      "       [   6,  476]]), array([[1475,    5],\n",
      "       [  11,  459]]), array([[1474,    3],\n",
      "       [   5,  468]]), array([[1466,    2],\n",
      "       [   7,  475]])] classification: \n",
      " ['              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1472\\n         1.0       1.00      0.98      0.99       478\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1469\\n         1.0       1.00      0.98      0.99       481\\n\\n    accuracy                           0.99      1950\\n   macro avg       1.00      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1483\\n         1.0       1.00      0.99      0.99       467\\n\\n    accuracy                           1.00      1950\\n   macro avg       1.00      0.99      1.00      1950\\nweighted avg       1.00      1.00      1.00      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1473\\n         1.0       1.00      0.97      0.99       477\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1479\\n         1.0       1.00      1.00      1.00       471\\n\\n    accuracy                           1.00      1950\\n   macro avg       1.00      1.00      1.00      1950\\nweighted avg       1.00      1.00      1.00      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1461\\n         1.0       1.00      0.97      0.98       489\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.98      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1468\\n         1.0       0.99      0.99      0.99       482\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1480\\n         1.0       0.99      0.98      0.98       470\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1477\\n         1.0       0.99      0.99      0.99       473\\n\\n    accuracy                           1.00      1950\\n   macro avg       1.00      0.99      0.99      1950\\nweighted avg       1.00      1.00      1.00      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1468\\n         1.0       1.00      0.99      0.99       482\\n\\n    accuracy                           1.00      1950\\n   macro avg       1.00      0.99      0.99      1950\\nweighted avg       1.00      1.00      1.00      1950\\n']\n",
      "Feature :     0 , importance : 0.05167\n",
      "Feature :     1 , importance : 0.12933\n",
      "Feature :     2 , importance : 0.01901\n",
      "Feature :     3 , importance : 0.04159\n",
      "Feature :     4 , importance : 0.27995\n",
      "Feature :     5 , importance : 0.04296\n",
      "Feature :     6 , importance : 0.29452\n",
      "Feature :     7 , importance : 0.05302\n",
      "Feature :     8 , importance : 0.01832\n",
      "Feature :     9 , importance : 0.05735\n",
      "Feature :    10 , importance : 0.01010\n",
      "Feature :    11 , importance : 0.00217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 12 artists>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance for random forest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cohen=[]\n",
    "score=[]\n",
    "confusion=[]\n",
    "class_out=[]\n",
    "for i in range(10): \n",
    "    model=RandomForestClassifier()\n",
    "    x=total_wine.drop(columns='wine_type')\n",
    "    y=total_wine['wine_type']\n",
    "    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "    scale=MinMaxScaler()\n",
    "    x_train_n= scale.fit_transform(x_train)\n",
    "    x_train_n= pd.DataFrame(x_train_n, columns=x_train.columns)\n",
    "    x_test_n= scale.fit_transform(x_test)\n",
    "    x_test_n= pd.DataFrame(x_test_n, columns=x_test.columns)\n",
    "    model.fit(x_train_n, y_train)\n",
    "    pred=model.predict(x_test_n)\n",
    "    scor=accuracy_score(pred, y_test)\n",
    "    score.append(scor)\n",
    "\n",
    "    con=confusion_matrix(y_test, pred)\n",
    "    confusion.append(con)\n",
    "    class_p= classification_report(y_test,pred)\n",
    "    class_out.append(class_p)\n",
    "    cohe=cohen_kappa_score(y_test, pred)\n",
    "    cohen.append(cohe)\n",
    "    i +=1\n",
    "print('score :\\n', np.mean(score),'\\ncohen: \\n',np.mean(cohen),'\\nconfusion \\n',confusion, 'classification: \\n',class_out)\n",
    "importance=model.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature : %5d , importance : %0.5f' %(i,v))\n",
    "plt.bar([x for x in range(len(importance))], importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :\n",
      " 0.9945128205128206 \n",
      "cohen: \n",
      " 0.9851885212573087 \n",
      "confusion \n",
      " [array([[1465,    2],\n",
      "       [   6,  477]]), array([[1492,    2],\n",
      "       [   5,  451]]), array([[1488,    4],\n",
      "       [  11,  447]]), array([[1457,    3],\n",
      "       [  10,  480]]), array([[1491,    2],\n",
      "       [  10,  447]]), array([[1440,    2],\n",
      "       [   7,  501]]), array([[1438,    3],\n",
      "       [   7,  502]]), array([[1466,    2],\n",
      "       [   8,  474]]), array([[1467,    2],\n",
      "       [   8,  473]]), array([[1441,    6],\n",
      "       [   7,  496]])] classification: \n",
      " ['              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1467\\n         1.0       1.00      0.99      0.99       483\\n\\n    accuracy                           1.00      1950\\n   macro avg       1.00      0.99      0.99      1950\\nweighted avg       1.00      1.00      1.00      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1494\\n         1.0       1.00      0.99      0.99       456\\n\\n    accuracy                           1.00      1950\\n   macro avg       1.00      0.99      0.99      1950\\nweighted avg       1.00      1.00      1.00      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1492\\n         1.0       0.99      0.98      0.98       458\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1460\\n         1.0       0.99      0.98      0.99       490\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1493\\n         1.0       1.00      0.98      0.99       457\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1442\\n         1.0       1.00      0.99      0.99       508\\n\\n    accuracy                           1.00      1950\\n   macro avg       1.00      0.99      0.99      1950\\nweighted avg       1.00      1.00      1.00      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1441\\n         1.0       0.99      0.99      0.99       509\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1468\\n         1.0       1.00      0.98      0.99       482\\n\\n    accuracy                           0.99      1950\\n   macro avg       1.00      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1469\\n         1.0       1.00      0.98      0.99       481\\n\\n    accuracy                           0.99      1950\\n   macro avg       1.00      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1447\\n         1.0       0.99      0.99      0.99       503\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n']\n",
      "Feature: 0, Score: 0.00097\n",
      "Feature: 1, Score: 0.00603\n",
      "Feature: 2, Score: 0.00053\n",
      "Feature: 3, Score: 0.10490\n",
      "Feature: 4, Score: 0.00435\n",
      "Feature: 5, Score: 0.00097\n",
      "Feature: 6, Score: 0.05573\n",
      "Feature: 7, Score: 0.25300\n",
      "Feature: 8, Score: -0.00004\n",
      "Feature: 9, Score: 0.00075\n",
      "Feature: 10, Score: 0.02375\n",
      "Feature: 11, Score: 0.00018\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importace for LinearDiscriminantAnalysis . This can be used for other models like knn ,..\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "cohen=[]\n",
    "score=[]\n",
    "confusion=[]\n",
    "class_out=[]\n",
    "for i in range(10): \n",
    "    model=LinearDiscriminantAnalysis()\n",
    "    x=total_wine.drop(columns='wine_type')\n",
    "    y=total_wine['wine_type']\n",
    "    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "    scale=MinMaxScaler()\n",
    "    x_train_n= scale.fit_transform(x_train)\n",
    "    x_train_n= pd.DataFrame(x_train_n, columns=x_train.columns)\n",
    "    x_test_n= scale.fit_transform(x_test)\n",
    "    x_test_n= pd.DataFrame(x_test_n, columns=x_test.columns)\n",
    "    model.fit(x_train_n, y_train)\n",
    "    pred=model.predict(x_test_n)\n",
    "    scor=accuracy_score(pred, y_test)\n",
    "    score.append(scor)\n",
    "\n",
    "    con=confusion_matrix(y_test, pred)\n",
    "    confusion.append(con)\n",
    "    class_p= classification_report(y_test,pred)\n",
    "    class_out.append(class_p)\n",
    "    cohe=cohen_kappa_score(y_test, pred)\n",
    "    cohen.append(cohe)\n",
    "    i +=1\n",
    "print('score :\\n', np.mean(score),'\\ncohen: \\n',np.mean(cohen),'\\nconfusion \\n',confusion, 'classification: \\n',class_out)\n",
    "res = permutation_importance(model, x_train_n, y_train, scoring='accuracy')\n",
    "importance = res.importances_mean\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    " print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :\n",
      " 0.9927179487179488 \n",
      "cohen: \n",
      " 0.9802638107905084 \n",
      "confusion \n",
      " [array([[1450,    6],\n",
      "       [  13,  481]]), array([[1481,    7],\n",
      "       [   9,  453]]), array([[1445,    2],\n",
      "       [  11,  492]]), array([[1475,    4],\n",
      "       [  13,  458]]), array([[1492,    6],\n",
      "       [  10,  442]]), array([[1479,    3],\n",
      "       [  11,  457]]), array([[1449,    5],\n",
      "       [   6,  490]]), array([[1465,    3],\n",
      "       [   8,  474]]), array([[1451,    4],\n",
      "       [   7,  488]]), array([[1464,    7],\n",
      "       [   7,  472]])] classification: \n",
      " ['              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1456\\n         1.0       0.99      0.97      0.98       494\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.98      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1488\\n         1.0       0.98      0.98      0.98       462\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1447\\n         1.0       1.00      0.98      0.99       503\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1479\\n         1.0       0.99      0.97      0.98       471\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.98      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1498\\n         1.0       0.99      0.98      0.98       452\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1482\\n         1.0       0.99      0.98      0.98       468\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1454\\n         1.0       0.99      0.99      0.99       496\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      1.00      1468\\n         1.0       0.99      0.98      0.99       482\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1455\\n         1.0       0.99      0.99      0.99       495\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1471\\n         1.0       0.99      0.99      0.99       479\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n']\n",
      "Feature: 0, Score: 0.00638\n",
      "Feature: 1, Score: 0.06197\n",
      "Feature: 2, Score: 0.00660\n",
      "Feature: 3, Score: 0.03554\n",
      "Feature: 4, Score: 0.21755\n",
      "Feature: 5, Score: 0.02111\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcWklEQVR4nO3df2xV9f348dcFbGs22qlogVBr56bSoaitQrvVbHNWGRpJltj9qprhDIlOauMfIropMalm+5jqFJRMZfwh1IShJtZJzTLAwIx0rTPGLC7KylwrlsUW/MaieL9/GJt1BeRW9L5bH4/kJNzD+56+zgmkz5x7e5vJZrPZAABI2KR8DwAA8EkECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMmbku8BjpYPP/ww/v3vf8fUqVMjk8nkexwA4Ahks9nYu3dvzJw5MyZNOvR9lAkTLP/+97+jrKws32MAAGOwa9eumDVr1iH/fsIEy9SpUyPioxMuLi7O8zQAwJEYHByMsrKy4e/jhzJhguXjl4GKi4sFCwCMM5/0dg5vugUAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkTcn3AADkxyk3P53vEfJi510L8z0CY+AOCwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJG1OwrFy5MioqKqKoqCiqqqpi69ath1z7hz/8IS666KI48cQTo7i4OGpqauLZZ58dtW7Dhg1RWVkZhYWFUVlZGRs3bhzLaADABJRzsLS1tUVTU1MsX748urq6oq6uLhYsWBA9PT0HXb9ly5a46KKLor29PTo7O+M73/lOXHbZZdHV1TW8Zvv27dHQ0BCNjY3x0ksvRWNjY1xxxRXxwgsvjP3MAIAJI5PNZrO5PGHevHlx7rnnxqpVq4b3zZ49OxYtWhQtLS1HdIxvfOMb0dDQEL/85S8jIqKhoSEGBwfjmWeeGV5zySWXxHHHHRfr1q07omMODg5GSUlJDAwMRHFxcQ5nBPDFdMrNT+d7hLzYedfCfI/AfznS79853WHZv39/dHZ2Rn19/Yj99fX1sW3btiM6xocffhh79+6N448/fnjf9u3bRx3z4osvPuJjAgAT25RcFvf398eBAweitLR0xP7S0tLo6+s7omP83//9X7z77rtxxRVXDO/r6+vL+ZhDQ0MxNDQ0/HhwcPCIvj4AMP6M6U23mUxmxONsNjtq38GsW7cubr/99mhra4uTTjrpUx2zpaUlSkpKhreysrIczgAAGE9yCpZp06bF5MmTR9352L1796g7JP+rra0tFi9eHI8//nh873vfG/F306dPz/mYy5Yti4GBgeFt165duZwKADCO5BQsBQUFUVVVFR0dHSP2d3R0RG1t7SGft27durj66qvjsccei4ULR7/ZqaamZtQxN23adNhjFhYWRnFx8YgNAJiYcnoPS0REc3NzNDY2RnV1ddTU1MTq1aujp6cnlixZEhEf3fl48803Y+3atRHxUaxceeWVce+998b8+fOH76Qce+yxUVJSEhERS5cujQsuuCDuvvvuuPzyy+PJJ5+M5557Lp5//vmjdZ4AwDiW83tYGhoaorW1NVasWBFnn312bNmyJdrb26O8vDwiInp7e0d8JstDDz0UH3zwQVx33XUxY8aM4W3p0qXDa2pra2P9+vXx6KOPxllnnRVr1qyJtra2mDdv3lE4RQBgvMv5c1hS5XNYAHLjc1hIwWfyOSwAAPkgWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkjSlYVq5cGRUVFVFUVBRVVVWxdevWQ67t7e2NH//4x3H66afHpEmToqmpadSaNWvWRCaTGbW99957YxkPAJhgcg6Wtra2aGpqiuXLl0dXV1fU1dXFggULoqen56Drh4aG4sQTT4zly5fH3LlzD3nc4uLi6O3tHbEVFRXlOh4AMAHlHCz33HNPLF68OK655pqYPXt2tLa2RllZWaxateqg60855ZS4995748orr4ySkpJDHjeTycT06dNHbAAAETkGy/79+6OzszPq6+tH7K+vr49t27Z9qkH27dsX5eXlMWvWrLj00kujq6vrUx0PAJg4cgqW/v7+OHDgQJSWlo7YX1paGn19fWMe4owzzog1a9bEU089FevWrYuioqL45je/Ga+99tohnzM0NBSDg4MjNgBgYhrTm24zmcyIx9lsdtS+XMyfPz9++tOfxty5c6Ouri4ef/zxOO200+K3v/3tIZ/T0tISJSUlw1tZWdmYvz4AkLacgmXatGkxefLkUXdTdu/ePequy6caatKkOO+88w57h2XZsmUxMDAwvO3ateuofX0AIC05BUtBQUFUVVVFR0fHiP0dHR1RW1t71IbKZrPR3d0dM2bMOOSawsLCKC4uHrEBABPTlFyf0NzcHI2NjVFdXR01NTWxevXq6OnpiSVLlkTER3c+3nzzzVi7du3wc7q7uyPiozfWvv3229Hd3R0FBQVRWVkZERF33HFHzJ8/P77+9a/H4OBg3HfffdHd3R0PPPDAUThFAGC8yzlYGhoaYs+ePbFixYro7e2NOXPmRHt7e5SXl0fERx8U97+fyXLOOecM/7mzszMee+yxKC8vj507d0ZExDvvvBPXXntt9PX1RUlJSZxzzjmxZcuWOP/88z/FqQEAE0Umm81m8z3E0TA4OBglJSUxMDDg5SGAI3DKzU/ne4S82HnXwnyPwH850u/ffpcQAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkb0zBsnLlyqioqIiioqKoqqqKrVu3HnJtb29v/PjHP47TTz89Jk2aFE1NTQddt2HDhqisrIzCwsKorKyMjRs3jmU0AGACyjlY2traoqmpKZYvXx5dXV1RV1cXCxYsiJ6enoOuHxoaihNPPDGWL18ec+fOPeia7du3R0NDQzQ2NsZLL70UjY2NccUVV8QLL7yQ63gAwASUyWaz2VyeMG/evDj33HNj1apVw/tmz54dixYtipaWlsM+99vf/nacffbZ0draOmJ/Q0NDDA4OxjPPPDO875JLLonjjjsu1q1bd0RzDQ4ORklJSQwMDERxcfGRnxDAF9QpNz+d7xHyYuddC/M9Av/lSL9/53SHZf/+/dHZ2Rn19fUj9tfX18e2bdvGNml8dIflf4958cUXH/aYQ0NDMTg4OGIDACamnIKlv78/Dhw4EKWlpSP2l5aWRl9f35iH6Ovry/mYLS0tUVJSMryVlZWN+esDAGkb05tuM5nMiMfZbHbUvs/6mMuWLYuBgYHhbdeuXZ/q6wMA6ZqSy+Jp06bF5MmTR9352L1796g7JLmYPn16zscsLCyMwsLCMX9NAGD8yOkOS0FBQVRVVUVHR8eI/R0dHVFbWzvmIWpqakYdc9OmTZ/qmADAxJHTHZaIiObm5mhsbIzq6uqoqamJ1atXR09PTyxZsiQiPnqp5s0334y1a9cOP6e7uzsiIvbt2xdvv/12dHd3R0FBQVRWVkZExNKlS+OCCy6Iu+++Oy6//PJ48skn47nnnovnn3/+KJwiADDe5RwsDQ0NsWfPnlixYkX09vbGnDlzor29PcrLyyPiow+K+9/PZDnnnHOG/9zZ2RmPPfZYlJeXx86dOyMiora2NtavXx+33npr3HbbbXHqqadGW1tbzJs371OcGgAwUeT8OSyp8jksALnxOSyk4DP5HBYAgHwQLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJEywAQPIECwCQvCn5HoCJ65Sbn873CHmx866F+R4BYMJxhwUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSN6ZgWblyZVRUVERRUVFUVVXF1q1bD7t+8+bNUVVVFUVFRfHVr341HnzwwRF/v2bNmshkMqO29957byzjAQATTM7B0tbWFk1NTbF8+fLo6uqKurq6WLBgQfT09Bx0/RtvvBHf//73o66uLrq6uuKWW26JG264ITZs2DBiXXFxcfT29o7YioqKxnZWAMCEMiXXJ9xzzz2xePHiuOaaayIiorW1NZ599tlYtWpVtLS0jFr/4IMPxsknnxytra0RETF79uzYsWNH/OY3v4kf/OAHw+symUxMnz59jKcBAExkOd1h2b9/f3R2dkZ9ff2I/fX19bFt27aDPmf79u2j1l988cWxY8eOeP/994f37du3L8rLy2PWrFlx6aWXRldX12FnGRoaisHBwREbADAx5RQs/f39ceDAgSgtLR2xv7S0NPr6+g76nL6+voOu/+CDD6K/vz8iIs4444xYs2ZNPPXUU7Fu3booKiqKb37zm/Haa68dcpaWlpYoKSkZ3srKynI5FQBgHBnTm24zmcyIx9lsdtS+T1r/3/vnz58fP/3pT2Pu3LlRV1cXjz/+eJx22mnx29/+9pDHXLZsWQwMDAxvu3btGsupAADjQE7vYZk2bVpMnjx51N2U3bt3j7qL8rHp06cfdP2UKVPihBNOOOhzJk2aFOedd95h77AUFhZGYWFhLuMDAONUTndYCgoKoqqqKjo6Okbs7+joiNra2oM+p6amZtT6TZs2RXV1dRxzzDEHfU42m43u7u6YMWNGLuMBABNUzi8JNTc3x+9+97t45JFH4tVXX40bb7wxenp6YsmSJRHx0Us1V1555fD6JUuWxD//+c9obm6OV199NR555JF4+OGH46abbhpec8cdd8Szzz4br7/+enR3d8fixYuju7t7+JgAwBdbzj/W3NDQEHv27IkVK1ZEb29vzJkzJ9rb26O8vDwiInp7e0d8JktFRUW0t7fHjTfeGA888EDMnDkz7rvvvhE/0vzOO+/EtddeG319fVFSUhLnnHNObNmyJc4///yjcIoAwHiXyX78DthxbnBwMEpKSmJgYCCKi4vzPQ4RccrNT+d7hLzYedfCfI8AR8T/UVJwpN+//S4hACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeVPyPQDAp3XKzU/ne4S82XnXwnyPAJ8Ld1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5U/I9AACMJ6fc/HS+R8iLnXctzOvXd4cFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgOQJFgAgeYIFAEieYAEAkidYAIDkCRYAIHmCBQBInmABAJInWACA5AkWACB5ggUASJ5gAQCSJ1gAgORNyfcA48EpNz+d7xHyYuddC/M9wheSf28Ao7nDAgAkT7AAAMkTLABA8gQLAJA8wQIAJG9MwbJy5cqoqKiIoqKiqKqqiq1btx52/ebNm6OqqiqKioriq1/9ajz44IOj1mzYsCEqKyujsLAwKisrY+PGjWMZDQCYgHIOlra2tmhqaorly5dHV1dX1NXVxYIFC6Knp+eg69944434/ve/H3V1ddHV1RW33HJL3HDDDbFhw4bhNdu3b4+GhoZobGyMl156KRobG+OKK66IF154YexnBgBMGDkHyz333BOLFy+Oa665JmbPnh2tra1RVlYWq1atOuj6Bx98ME4++eRobW2N2bNnxzXXXBM/+9nP4je/+c3wmtbW1rjoooti2bJlccYZZ8SyZcviwgsvjNbW1jGfGAAwceT0wXH79++Pzs7OuPnmm0fsr6+vj23bth30Odu3b4/6+voR+y6++OJ4+OGH4/33349jjjkmtm/fHjfeeOOoNYcLlqGhoRgaGhp+PDAwEBERg4ODuZzSEflw6P8d9WOOB5/2WrpuY+O65e6Les0iXLex8H90bD6L76//fdxsNnvYdTkFS39/fxw4cCBKS0tH7C8tLY2+vr6DPqevr++g6z/44IPo7++PGTNmHHLNoY4ZEdHS0hJ33HHHqP1lZWVHejp8gpLWfE8wPrluY+O6jY3rljvXbGw+6+u2d+/eKCkpOeTfj+mj+TOZzIjH2Wx21L5PWv+/+3M95rJly6K5uXn48Ycffhj/+c9/4oQTTjjs88aTwcHBKCsri127dkVxcXG+xxk3XLexcd3GxnXLnWs2NhP1umWz2di7d2/MnDnzsOtyCpZp06bF5MmTR9352L1796g7JB+bPn36QddPmTIlTjjhhMOuOdQxIyIKCwujsLBwxL6vfOUrR3oq40pxcfGE+sf5eXHdxsZ1GxvXLXeu2dhMxOt2uDsrH8vpTbcFBQVRVVUVHR0dI/Z3dHREbW3tQZ9TU1Mzav2mTZuiuro6jjnmmMOuOdQxAYAvlpxfEmpubo7Gxsaorq6OmpqaWL16dfT09MSSJUsi4qOXat58881Yu3ZtREQsWbIk7r///mhubo6f//znsX379nj44Ydj3bp1w8dcunRpXHDBBXH33XfH5ZdfHk8++WQ899xz8fzzzx+l0wQAxrOcg6WhoSH27NkTK1asiN7e3pgzZ060t7dHeXl5RET09vaO+EyWioqKaG9vjxtvvDEeeOCBmDlzZtx3333xgx/8YHhNbW1trF+/Pm699da47bbb4tRTT422traYN2/eUTjF8auwsDB+9atfjXrpi8Nz3cbGdRsb1y13rtnYfNGvWyb7ST9HBACQZ36XEACQPMECACRPsAAAyRMsAEDyBEvCVq5cGRUVFVFUVBRVVVWxdevWfI+UtC1btsRll10WM2fOjEwmE0888US+R0peS0tLnHfeeTF16tQ46aSTYtGiRfH3v/8932Mlb9WqVXHWWWcNf4BXTU1NPPPMM/kea9xpaWmJTCYTTU1N+R4labfffntkMpkR2/Tp0/M91udOsCSqra0tmpqaYvny5dHV1RV1dXWxYMGCET8yzkjvvvtuzJ07N+6///58jzJubN68Oa677rr4y1/+Eh0dHfHBBx9EfX19vPvuu/keLWmzZs2Ku+66K3bs2BE7duyI7373u3H55ZfHK6+8ku/Rxo0XX3wxVq9eHWeddVa+RxkXvvGNb0Rvb+/w9vLLL+d7pM+dH2tO1Lx58+Lcc8+NVatWDe+bPXt2LFq0KFpaWvI42fiQyWRi48aNsWjRonyPMq68/fbbcdJJJ8XmzZvjggsuyPc448rxxx8fv/71r2Px4sX5HiV5+/bti3PPPTdWrlwZd955Z5x99tnR2tqa77GSdfvtt8cTTzwR3d3d+R4lr9xhSdD+/fujs7Mz6uvrR+yvr6+Pbdu25WkqvggGBgYi4qNvvhyZAwcOxPr16+Pdd9+NmpqafI8zLlx33XWxcOHC+N73vpfvUcaN1157LWbOnBkVFRXxwx/+MF5//fV8j/S5G9Nva+az1d/fHwcOHBj1yx9LS0tH/ZJIOFqy2Ww0NzfHt771rZgzZ06+x0neyy+/HDU1NfHee+/Fl7/85di4cWNUVlbme6zkrV+/Pv7617/Giy++mO9Rxo158+bF2rVr47TTTou33nor7rzzzqitrY1XXnll+JcIfxEIloRlMpkRj7PZ7Kh9cLRcf/318be//c3v8DpCp59+enR3d8c777wTGzZsiKuuuio2b94sWg5j165dsXTp0ti0aVMUFRXle5xxY8GCBcN/PvPMM6OmpiZOPfXU+P3vfx/Nzc15nOzzJVgSNG3atJg8efKouym7d+8eddcFjoZf/OIX8dRTT8WWLVti1qxZ+R5nXCgoKIivfe1rERFRXV0dL774Ytx7773x0EMP5XmydHV2dsbu3bujqqpqeN+BAwdiy5Ytcf/998fQ0FBMnjw5jxOOD1/60pfizDPPjNdeey3fo3yuvIclQQUFBVFVVRUdHR0j9nd0dERtbW2epmIiymazcf3118cf/vCH+NOf/hQVFRX5HmncymazMTQ0lO8xknbhhRfGyy+/HN3d3cNbdXV1/OQnP4nu7m6xcoSGhobi1VdfjRkzZuR7lM+VOyyJam5ujsbGxqiuro6amppYvXp19PT0xJIlS/I9WrL27dsX//jHP4Yfv/HGG9Hd3R3HH398nHzyyXmcLF3XXXddPPbYY/Hkk0/G1KlTh+/qlZSUxLHHHpvn6dJ1yy23xIIFC6KsrCz27t0b69evjz//+c/xxz/+Md+jJW3q1Kmj3h/1pS99KU444QTvmzqMm266KS677LI4+eSTY/fu3XHnnXfG4OBgXHXVVfke7XMlWBLV0NAQe/bsiRUrVkRvb2/MmTMn2tvbo7y8PN+jJWvHjh3xne98Z/jxx6/tXnXVVbFmzZo8TZW2j39s/tvf/vaI/Y8++mhcffXVn/9A48Rbb70VjY2N0dvbGyUlJXHWWWfFH//4x7jooovyPRoT0L/+9a/40Y9+FP39/XHiiSfG/Pnz4y9/+csX7vuBz2EBAJLnPSwAQPIECwCQPMECACRPsAAAyRMsAEDyBAsAkDzBAgAkT7AAAMkTLABA8gQLAJA8wQIAJE+wAADJ+/9oTHhyYzszNwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# removing Features based on feature importace for LinearDiscriminantAnalysis . This can be used for other models like knn ,..\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "cohen=[]\n",
    "score=[]\n",
    "confusion=[]\n",
    "class_out=[]\n",
    "for i in range(10): \n",
    "    model=LinearDiscriminantAnalysis()\n",
    "    x=total_wine.drop(columns=['fixed_acidity','citric_acid','free_sulfur_dioxide','pH','sulphates','quality','wine_type'])\n",
    "    y=total_wine['wine_type']\n",
    "    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "    scale=MinMaxScaler()\n",
    "    x_train_n= scale.fit_transform(x_train)\n",
    "    x_train_n= pd.DataFrame(x_train_n, columns=x_train.columns)\n",
    "    x_test_n= scale.fit_transform(x_test)\n",
    "    x_test_n= pd.DataFrame(x_test_n, columns=x_test.columns)\n",
    "    model.fit(x_train_n, y_train)\n",
    "    pred=model.predict(x_test_n)\n",
    "    scor=accuracy_score(pred, y_test)\n",
    "    score.append(scor)\n",
    "\n",
    "    con=confusion_matrix(y_test, pred)\n",
    "    confusion.append(con)\n",
    "    class_p= classification_report(y_test,pred)\n",
    "    class_out.append(class_p)\n",
    "    cohe=cohen_kappa_score(y_test, pred)\n",
    "    cohen.append(cohe)\n",
    "    i +=1\n",
    "print('score :\\n', np.mean(score),'\\ncohen: \\n',np.mean(cohen),'\\nconfusion \\n',confusion, 'classification: \\n',class_out)\n",
    "res = permutation_importance(model, x_train_n, y_train, scoring='accuracy')\n",
    "importance = res.importances_mean\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    " print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :\n",
      " 0.9929230769230768 \n",
      "cohen: \n",
      " 0.9810099511984944 \n",
      "confusion \n",
      " [array([[1454,    9],\n",
      "       [   7,  480]]), array([[1468,    8],\n",
      "       [   3,  471]]), array([[1457,    6],\n",
      "       [  10,  477]]), array([[1444,    3],\n",
      "       [   7,  496]]), array([[1465,    7],\n",
      "       [  11,  467]]), array([[1443,    7],\n",
      "       [   7,  493]]), array([[1454,    7],\n",
      "       [   5,  484]]), array([[1485,    7],\n",
      "       [   6,  452]]), array([[1459,    3],\n",
      "       [  13,  475]]), array([[1466,    6],\n",
      "       [   6,  472]])] classification: \n",
      " ['              precision    recall  f1-score   support\\n\\n         0.0       1.00      0.99      0.99      1463\\n         1.0       0.98      0.99      0.98       487\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      0.99      1.00      1476\\n         1.0       0.98      0.99      0.99       474\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1463\\n         1.0       0.99      0.98      0.98       487\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1447\\n         1.0       0.99      0.99      0.99       503\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1472\\n         1.0       0.99      0.98      0.98       478\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1450\\n         1.0       0.99      0.99      0.99       500\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1461\\n         1.0       0.99      0.99      0.99       489\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1492\\n         1.0       0.98      0.99      0.99       458\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      1.00      0.99      1462\\n         1.0       0.99      0.97      0.98       488\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00      1472\\n         1.0       0.99      0.99      0.99       478\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.99      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature :     0 , importance 0.00652 \n",
      "Feature :     1 , importance 0.02143 \n",
      "Feature :     2 , importance 0.00296 \n",
      "Feature :     3 , importance 0.02261 \n",
      "Feature :     4 , importance 0.03608 \n",
      "Feature :     5 , importance 0.00281 \n",
      "Feature :     6 , importance 0.05664 \n",
      "Feature :     7 , importance 0.01913 \n",
      "Feature :     8 , importance 0.01104 \n",
      "Feature :     9 , importance 0.01121 \n",
      "Feature :    10 , importance 0.00288 \n",
      "Feature :    11 , importance 0.00355 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 12 artists>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhGklEQVR4nO3df2zU9eHH8dfZH3foaJV2tna25eowrXYK3qlr9cRFPQLMzYzN6gSMUJcGHbQXFil1QWugiB1pENqmWEaYil1SnSx2k9NpQekm1FYNa3TGQjvopSnbWtTYQvl8/zDcvre7Ild/3Lvl+Ug+f9y778993p8L4Z753C+bZVmWAAAADHZerBcAAADwRQgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMaLj/UCviqnTp3S0aNHNXXqVNlstlgvBwAAnAXLsnT8+HFlZGTovPPGvo4yaYLl6NGjyszMjPUyAADAOPT29urSSy8d8++TJlimTp0q6fMTTkpKivFqAADA2RgaGlJmZmbweXwskyZYTr8MlJSURLAAADDBfNHbOXjTLQAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjBcf6wUAwHhMX/VSTI57aP38mBwXONdxhQUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGC8cQVLbW2tnE6nHA6HXC6X9u7de8b5ra2tcrlccjgcysnJUX19fcjft2/fLpvNFrZ99tln41keAACYZKIOlqamJpWWlqqiokIdHR3yeDyaO3euenp6Is7v7u7WvHnz5PF41NHRodWrV2v58uVqbm4OmZeUlKS+vr6QzeFwjO+sAADApBIf7Q4bN27U0qVLVVxcLEmqqanRyy+/rLq6OlVVVYXNr6+vV1ZWlmpqaiRJeXl5OnDggKqrq7VgwYLgPJvNpvT09HGeBgAAmMyiusIyMjKi9vZ2eb3ekHGv16t9+/ZF3KetrS1s/pw5c3TgwAGdOHEiOPbxxx8rOztbl156qX74wx+qo6MjmqUBAIBJLKpgGRgY0OjoqNLS0kLG09LSFAgEIu4TCAQizj958qQGBgYkSbm5udq+fbt27dqlnTt3yuFw6IYbbtA//vGPMdcyPDysoaGhkA0AAExO43rTrc1mC7ltWVbY2BfN///j3//+97Vw4UJdffXV8ng8+v3vf6/LL79cTz755Jj3WVVVpeTk5OCWmZk5nlMBAAATQFTBkpqaqri4uLCrKf39/WFXUU5LT0+POD8+Pl4pKSmRF3Xeebr22mvPeIWlvLxcg4ODwa23tzeaUwEAABNIVMGSmJgol8slv98fMu73+1VYWBhxn4KCgrD5u3fvltvtVkJCQsR9LMtSZ2enLrnkkjHXYrfblZSUFLIBAIDJKeqXhHw+n5566ilt27ZNXV1dKisrU09Pj0pKSiR9fuVj8eLFwfklJSU6fPiwfD6furq6tG3bNjU2NmrlypXBOY8++qhefvllffTRR+rs7NTSpUvV2dkZvE8AAHBui/pjzUVFRTp27JgqKyvV19en/Px8tbS0KDs7W5LU19cX8p0sTqdTLS0tKisr05YtW5SRkaFNmzaFfKT5P//5j37xi18oEAgoOTlZs2bN0p49e3Tdddd9BacIAAAmOpt1+h2wE9zQ0JCSk5M1ODjIy0PAOWD6qpdictxD6+fH5LjAZHW2z9/8lhAAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHjjCpba2lo5nU45HA65XC7t3bv3jPNbW1vlcrnkcDiUk5Oj+vr6Mec+99xzstlsuuOOO8azNAAAMAlFHSxNTU0qLS1VRUWFOjo65PF4NHfuXPX09ESc393drXnz5snj8aijo0OrV6/W8uXL1dzcHDb38OHDWrlypTweT/RnAgAAJq2og2Xjxo1aunSpiouLlZeXp5qaGmVmZqquri7i/Pr6emVlZammpkZ5eXkqLi7WkiVLVF1dHTJvdHRU99xzjx599FHl5OSM72wAAMCkFFWwjIyMqL29XV6vN2Tc6/Vq3759Efdpa2sLmz9nzhwdOHBAJ06cCI5VVlbq29/+tpYuXXpWaxkeHtbQ0FDIBgAAJqeogmVgYECjo6NKS0sLGU9LS1MgEIi4TyAQiDj/5MmTGhgYkCS9+eabamxs1NatW896LVVVVUpOTg5umZmZ0ZwKAACYQMb1plubzRZy27KssLEvmn96/Pjx41q4cKG2bt2q1NTUs15DeXm5BgcHg1tvb28UZwAAACaS+Ggmp6amKi4uLuxqSn9/f9hVlNPS09Mjzo+Pj1dKSooOHjyoQ4cO6fbbbw/+/dSpU58vLj5e77//vi677LKw+7Xb7bLb7dEsHwAATFBRXWFJTEyUy+WS3+8PGff7/SosLIy4T0FBQdj83bt3y+12KyEhQbm5uXrvvffU2dkZ3H70ox/pBz/4gTo7O3mpBwAARHeFRZJ8Pp8WLVokt9utgoICNTQ0qKenRyUlJZI+f6nmyJEj2rFjhySppKREmzdvls/n0/3336+2tjY1NjZq586dkiSHw6H8/PyQY1x44YWSFDYOAADOTVEHS1FRkY4dO6bKykr19fUpPz9fLS0tys7OliT19fWFfCeL0+lUS0uLysrKtGXLFmVkZGjTpk1asGDBV3cWAABgUrNZp98BO8ENDQ0pOTlZg4ODSkpKivVyAHzNpq96KSbHPbR+fkyOC0xWZ/v8zW8JAQAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjxcd6AQCk6ateitmxD62fH7NjA8DZ4goLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMN64gqW2tlZOp1MOh0Mul0t79+494/zW1la5XC45HA7l5OSovr4+5O/PP/+83G63LrzwQl1wwQWaOXOmfve7341naQAAYBKKOliamppUWlqqiooKdXR0yOPxaO7cuerp6Yk4v7u7W/PmzZPH41FHR4dWr16t5cuXq7m5OThn2rRpqqioUFtbm959913dd999uu+++/Tyyy+P/8wAAMCkYbMsy4pmh+uvv17XXHON6urqgmN5eXm64447VFVVFTb/oYce0q5du9TV1RUcKykp0TvvvKO2trYxj3PNNddo/vz5euyxx85qXUNDQ0pOTtbg4KCSkpKiOCMg9qaveilmxz60fn7Mjv1lxOoxm6iPF2Cqs33+juoKy8jIiNrb2+X1ekPGvV6v9u3bF3Gftra2sPlz5szRgQMHdOLEibD5lmXp1Vdf1fvvv6+bbrppzLUMDw9raGgoZAMAAJNTVMEyMDCg0dFRpaWlhYynpaUpEAhE3CcQCEScf/LkSQ0MDATHBgcH9a1vfUuJiYmaP3++nnzySd12221jrqWqqkrJycnBLTMzM5pTAQAAE8i43nRrs9lCbluWFTb2RfP/d3zq1Knq7OzU/v37tXbtWvl8Pr3++utj3md5ebkGBweDW29v7zjOBAAATATx0UxOTU1VXFxc2NWU/v7+sKsop6Wnp0ecHx8fr5SUlODYeeedp+9+97uSpJkzZ6qrq0tVVVW6+eabI96v3W6X3W6PZvkAAGCCiuoKS2Jiolwul/x+f8i43+9XYWFhxH0KCgrC5u/evVtut1sJCQljHsuyLA0PD0ezPAAAMElFdYVFknw+nxYtWiS3262CggI1NDSop6dHJSUlkj5/qebIkSPasWOHpM8/EbR582b5fD7df//9amtrU2Njo3bu3Bm8z6qqKrndbl122WUaGRlRS0uLduzYEfJJJAAAcO6KOliKiop07NgxVVZWqq+vT/n5+WppaVF2drYkqa+vL+Q7WZxOp1paWlRWVqYtW7YoIyNDmzZt0oIFC4JzPvnkEy1btkz//Oc/NWXKFOXm5urpp59WUVHRV3CKAABgoov6e1hMxfewYCLje1iix/ewAJPD1/I9LAAAALFAsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHjxsV4A8E2avuqlmBz30Pr5MTkuAEwWXGEBAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPH4WPMEFquP6Ep8TBcA8M3iCgsAADAewQIAAIxHsAAAAOMRLAAAwHjjCpba2lo5nU45HA65XC7t3bv3jPNbW1vlcrnkcDiUk5Oj+vr6kL9v3bpVHo9HF110kS666CLdeuuteuutt8azNAAAMAlFHSxNTU0qLS1VRUWFOjo65PF4NHfuXPX09ESc393drXnz5snj8aijo0OrV6/W8uXL1dzcHJzz+uuv6+6779Zrr72mtrY2ZWVlyev16siRI+M/MwAAMGlEHSwbN27U0qVLVVxcrLy8PNXU1CgzM1N1dXUR59fX1ysrK0s1NTXKy8tTcXGxlixZourq6uCcZ555RsuWLdPMmTOVm5urrVu36tSpU3r11VfHf2YAAGDSiCpYRkZG1N7eLq/XGzLu9Xq1b9++iPu0tbWFzZ8zZ44OHDigEydORNzn008/1YkTJzRt2rQx1zI8PKyhoaGQDQAATE5RBcvAwIBGR0eVlpYWMp6WlqZAIBBxn0AgEHH+yZMnNTAwEHGfVatW6Tvf+Y5uvfXWMddSVVWl5OTk4JaZmRnNqQAAgAlkXG+6tdlsIbctywob+6L5kcYlacOGDdq5c6eef/55ORyOMe+zvLxcg4ODwa23tzeaUwAAABNIVF/Nn5qaqri4uLCrKf39/WFXUU5LT0+POD8+Pl4pKSkh49XV1Vq3bp1eeeUVXXXVVWdci91ul91uj2b5AABggorqCktiYqJcLpf8fn/IuN/vV2FhYcR9CgoKwubv3r1bbrdbCQkJwbEnnnhCjz32mP785z/L7XZHsywAADDJRf2SkM/n01NPPaVt27apq6tLZWVl6unpUUlJiaTPX6pZvHhxcH5JSYkOHz4sn8+nrq4ubdu2TY2NjVq5cmVwzoYNG/Twww9r27Ztmj59ugKBgAKBgD7++OOv4BQBAMBEF/WvNRcVFenYsWOqrKxUX1+f8vPz1dLSouzsbElSX19fyHeyOJ1OtbS0qKysTFu2bFFGRoY2bdqkBQsWBOfU1tZqZGREP/3pT0OOtWbNGj3yyCPjPDUA+ObF6lfU+QV1THZRB4skLVu2TMuWLYv4t+3bt4eNzZ49W2+//faY93fo0KHxLAMAAJwj+C0hAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8eJjvQAAwLlr+qqXYnbsQ+vnx+zYiB7BAgDnAMIAEx0vCQEAAOONK1hqa2vldDrlcDjkcrm0d+/eM85vbW2Vy+WSw+FQTk6O6uvrQ/5+8OBBLViwQNOnT5fNZlNNTc14lgUAACapqIOlqalJpaWlqqioUEdHhzwej+bOnauenp6I87u7uzVv3jx5PB51dHRo9erVWr58uZqbm4NzPv30U+Xk5Gj9+vVKT08f/9kAAIBJKepg2bhxo5YuXari4mLl5eWppqZGmZmZqqurizi/vr5eWVlZqqmpUV5enoqLi7VkyRJVV1cH51x77bV64okndNddd8lut4//bAAAwKQUVbCMjIyovb1dXq83ZNzr9Wrfvn0R92lrawubP2fOHB04cEAnTpyIcrn/NTw8rKGhoZANAABMTlEFy8DAgEZHR5WWlhYynpaWpkAgEHGfQCAQcf7Jkyc1MDAQ5XL/q6qqSsnJycEtMzNz3PcFAADMNq433dpstpDblmWFjX3R/Ejj0SgvL9fg4GBw6+3tHfd9AQAAs0X1PSypqamKi4sLu5rS398fdhXltPT09Ijz4+PjlZKSEuVy/8tut/N+FwAAzhFRXWFJTEyUy+WS3+8PGff7/SosLIy4T0FBQdj83bt3y+12KyEhIcrlAgCAc1HULwn5fD499dRT2rZtm7q6ulRWVqaenh6VlJRI+vylmsWLFwfnl5SU6PDhw/L5fOrq6tK2bdvU2NiolStXBueMjIyos7NTnZ2dGhkZ0ZEjR9TZ2akPP/zwKzhFAAAw0UX91fxFRUU6duyYKisr1dfXp/z8fLW0tCg7O1uS1NfXF/KdLE6nUy0tLSorK9OWLVuUkZGhTZs2acGCBcE5R48e1axZs4K3q6urVV1drdmzZ+v111//EqcHAAAmg3H9ltCyZcu0bNmyiH/bvn172Njs2bP19ttvj3l/06dPD74RFwAA4H/xW0IAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIwXH+sFTATTV70Us2MfWj8/ZscGAMAUXGEBAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMaLj/UCAADA2Zu+6qWYHPfQ+vkxOe5pXGEBAADGI1gAAIDxCBYAAGA83sOCr8W5+horgMkhVv+HSfw/NhaCBcCY+E8bgCl4SQgAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGC8cQVLbW2tnE6nHA6HXC6X9u7de8b5ra2tcrlccjgcysnJUX19fdic5uZmXXHFFbLb7briiiv0wgsvjGdpAABgEoo6WJqamlRaWqqKigp1dHTI4/Fo7ty56unpiTi/u7tb8+bNk8fjUUdHh1avXq3ly5erubk5OKetrU1FRUVatGiR3nnnHS1atEh33nmn/va3v43/zAAAwKQRdbBs3LhRS5cuVXFxsfLy8lRTU6PMzEzV1dVFnF9fX6+srCzV1NQoLy9PxcXFWrJkiaqrq4NzampqdNttt6m8vFy5ubkqLy/XLbfcopqamnGfGAAAmDzio5k8MjKi9vZ2rVq1KmTc6/Vq3759Efdpa2uT1+sNGZszZ44aGxt14sQJJSQkqK2tTWVlZWFzzhQsw8PDGh4eDt4eHByUJA0NDUVzSmfl1PCnX/l9nq0znY+p65JitzbWFT3+jUWHdUVvIv4bM3Vdkrn/xr7s/VqWdeaJVhSOHDliSbLefPPNkPG1a9dal19+ecR9ZsyYYa1duzZk7M0337QkWUePHrUsy7ISEhKsZ555JmTOM888YyUmJo65ljVr1liS2NjY2NjY2CbB1tvbe8YGieoKy2k2my3ktmVZYWNfNP9/x6O9z/Lycvl8vuDtU6dO6V//+pdSUlLOuN83bWhoSJmZmert7VVSUlKsl2M8Hq/o8HhFj8csOjxe0eMxi45lWTp+/LgyMjLOOC+qYElNTVVcXJwCgUDIeH9/v9LS0iLuk56eHnF+fHy8UlJSzjhnrPuUJLvdLrvdHjJ24YUXnu2pfOOSkpL4hxsFHq/o8HhFj8csOjxe0eMxO3vJyclfOCeqN90mJibK5XLJ7/eHjPv9fhUWFkbcp6CgIGz+7t275Xa7lZCQcMY5Y90nAAA4t0T9kpDP59OiRYvkdrtVUFCghoYG9fT0qKSkRNLnL9UcOXJEO3bskCSVlJRo8+bN8vl8uv/++9XW1qbGxkbt3LkzeJ8rVqzQTTfdpMcff1w//vGP9eKLL+qVV17RG2+88RWdJgAAmMiiDpaioiIdO3ZMlZWV6uvrU35+vlpaWpSdnS1J6uvrC/lOFqfTqZaWFpWVlWnLli3KyMjQpk2btGDBguCcwsJCPffcc3r44Yf161//Wpdddpmampp0/fXXfwWnGFt2u11r1qwJe/kKkfF4RYfHK3o8ZtHh8Yoej9nXw2ZZX/Q5IgAAgNjit4QAAIDxCBYAAGA8ggUAABiPYAEAAMYjWL5GtbW1cjqdcjgccrlc2rt3b6yXZKyqqipde+21mjp1qi6++GLdcccdev/992O9rAmjqqpKNptNpaWlsV6KsY4cOaKFCxcqJSVF559/vmbOnKn29vZYL8tYJ0+e1MMPPyyn06kpU6YoJydHlZWVOnXqVKyXZoQ9e/bo9ttvV0ZGhmw2m/7whz+E/N2yLD3yyCPKyMjQlClTdPPNN+vgwYOxWewkQbB8TZqamlRaWqqKigp1dHTI4/Fo7ty5IR/5xn+1trbqgQce0F//+lf5/X6dPHlSXq9Xn3zySayXZrz9+/eroaFBV111VayXYqx///vfuuGGG5SQkKA//elP+vvf/67f/OY3Rn87dqw9/vjjqq+v1+bNm9XV1aUNGzboiSee0JNPPhnrpRnhk08+0dVXX63NmzdH/PuGDRu0ceNGbd68Wfv371d6erpuu+02HT9+/Bte6SRyxl8awrhdd911VklJSchYbm6utWrVqhitaGLp7++3JFmtra2xXorRjh8/bs2YMcPy+/3W7NmzrRUrVsR6SUZ66KGHrBtvvDHWy5hQ5s+fby1ZsiRk7Cc/+Ym1cOHCGK3IXJKsF154IXj71KlTVnp6urV+/frg2GeffWYlJydb9fX1MVjh5MAVlq/ByMiI2tvb5fV6Q8a9Xq/27dsXo1VNLIODg5KkadOmxXglZnvggQc0f/583XrrrbFeitF27dolt9utn/3sZ7r44os1a9Ysbd26NdbLMtqNN96oV199VR988IEk6Z133tEbb7yhefPmxXhl5uvu7lYgEAh5DrDb7Zo9ezbPAV/CuH6tGWc2MDCg0dHRsB9vTEtLC/uRR4SzLEs+n0833nij8vPzY70cYz333HN6++23tX///lgvxXgfffSR6urq5PP5tHr1ar311ltavny57Ha7Fi9eHOvlGemhhx7S4OCgcnNzFRcXp9HRUa1du1Z33313rJdmvNP/z0d6Djh8+HAsljQpECxfI5vNFnLbsqywMYR78MEH9e677/JbUmfQ29urFStWaPfu3XI4HLFejvFOnTolt9utdevWSZJmzZqlgwcPqq6ujmAZQ1NTk55++mk9++yzuvLKK9XZ2anS0lJlZGTo3nvvjfXyJgSeA75aBMvXIDU1VXFxcWFXU/r7+8OKG6F++ctfateuXdqzZ48uvfTSWC/HWO3t7erv75fL5QqOjY6Oas+ePdq8ebOGh4cVFxcXwxWa5ZJLLtEVV1wRMpaXl6fm5uYYrch8v/rVr7Rq1SrdddddkqTvfe97Onz4sKqqqgiWL5Ceni7p8ystl1xySXCc54Avh/ewfA0SExPlcrnk9/tDxv1+vwoLC2O0KrNZlqUHH3xQzz//vP7yl7/I6XTGeklGu+WWW/Tee++ps7MzuLndbt1zzz3q7OwkVv7HDTfcEPYx+Q8++CD4o60I9+mnn+q880KfIuLi4vhY81lwOp1KT08PeQ4YGRlRa2srzwFfAldYviY+n0+LFi2S2+1WQUGBGhoa1NPTo5KSklgvzUgPPPCAnn32Wb344ouaOnVq8OpUcnKypkyZEuPVmWfq1Klh7++54IILlJKSwvt+IigrK1NhYaHWrVunO++8U2+99ZYaGhrU0NAQ66UZ6/bbb9fatWuVlZWlK6+8Uh0dHdq4caOWLFkS66UZ4eOPP9aHH34YvN3d3a3Ozk5NmzZNWVlZKi0t1bp16zRjxgzNmDFD69at0/nnn6+f//znMVz1BBfbDylNblu2bLGys7OtxMRE65prruEjumcgKeL229/+NtZLmzD4WPOZ/fGPf7Ty8/Mtu91u5ebmWg0NDbFektGGhoasFStWWFlZWZbD4bBycnKsiooKa3h4ONZLM8Jrr70W8f+se++917Kszz/avGbNGis9Pd2y2+3WTTfdZL333nuxXfQEZ7Msy4pRKwEAAJwV3sMCAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAw3v8BNAhfnEG2p58AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "cohen=[]\n",
    "score=[]\n",
    "confusion=[]\n",
    "class_out=[]\n",
    "for i in range(10): \n",
    "    model=KNeighborsClassifier()\n",
    "    x=total_wine.drop(columns='wine_type')\n",
    "    y=total_wine['wine_type']\n",
    "    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "    scale=MinMaxScaler()\n",
    "    x_train_n= scale.fit_transform(x_train)\n",
    "    x_train_n= pd.DataFrame(x_train_n, columns=x_train.columns)\n",
    "    x_test_n= scale.fit_transform(x_test)\n",
    "    x_test_n= pd.DataFrame(x_test_n, columns=x_test.columns)\n",
    "    model.fit(x_train_n, y_train)\n",
    "    pred=model.predict(x_test_n)\n",
    "    scor=accuracy_score(pred, y_test)\n",
    "    score.append(scor)\n",
    "\n",
    "    con=confusion_matrix(y_test, pred)\n",
    "    confusion.append(con)\n",
    "    class_p= classification_report(y_test,pred)\n",
    "    class_out.append(class_p)\n",
    "    cohe=cohen_kappa_score(y_test, pred)\n",
    "    cohen.append(cohe)\n",
    "    i +=1\n",
    "print('score :\\n', np.mean(score),'\\ncohen: \\n',np.mean(cohen),'\\nconfusion \\n',confusion, 'classification: \\n',class_out)\n",
    "res=permutation_importance(model, x_train_n,y_train, scoring='f1')\n",
    "importance=res.importances_mean\n",
    "for i, v in enumerate(importance):\n",
    "    print('Feature : %5d , importance %0.5f ' %(i,v))\n",
    "plt.bar([x for x in range(len(importance))], importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :\n",
      " 0.9843589743589745 \n",
      "cohen: \n",
      " 0.9575074859769718 \n",
      "confusion \n",
      " [array([[1445,   14],\n",
      "       [  25,  466]]), array([[1464,   16],\n",
      "       [  12,  458]]), array([[1448,   14],\n",
      "       [  18,  470]]), array([[1479,   11],\n",
      "       [  19,  441]]), array([[1457,    8],\n",
      "       [  23,  462]]), array([[1478,   12],\n",
      "       [  12,  448]]), array([[1472,   13],\n",
      "       [  17,  448]]), array([[1433,   18],\n",
      "       [  13,  486]]), array([[1479,   12],\n",
      "       [  15,  444]]), array([[1456,   18],\n",
      "       [  15,  461]])] classification: \n",
      " ['              precision    recall  f1-score   support\\n\\n         0.0       0.98      0.99      0.99      1459\\n         1.0       0.97      0.95      0.96       491\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.97      0.97      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1480\\n         1.0       0.97      0.97      0.97       470\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1462\\n         1.0       0.97      0.96      0.97       488\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1490\\n         1.0       0.98      0.96      0.97       460\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.98      0.99      0.99      1465\\n         1.0       0.98      0.95      0.97       485\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.97      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1490\\n         1.0       0.97      0.97      0.97       460\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1485\\n         1.0       0.97      0.96      0.97       465\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1451\\n         1.0       0.96      0.97      0.97       499\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1491\\n         1.0       0.97      0.97      0.97       459\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1474\\n         1.0       0.96      0.97      0.97       476\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n']\n",
      "Feature :     0 , importance 0.00169 \n",
      "Feature :     1 , importance 0.04707 \n",
      "Feature :     2 , importance 0.01548 \n",
      "Feature :     3 , importance 0.00471 \n",
      "Feature :     4 , importance 0.28194 \n",
      "Feature :     5 , importance 0.00339 \n",
      "Feature :     6 , importance 0.27368 \n",
      "Feature :     7 , importance 0.16624 \n",
      "Feature :     8 , importance 0.01446 \n",
      "Feature :     9 , importance 0.05070 \n",
      "Feature :    10 , importance 0.03960 \n",
      "Feature :    11 , importance 0.00134 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 12 artists>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Although decision tree has own feature_importance, but permutation can also be used for it (results of both show almost similar outcomes)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cohen=[]\n",
    "score=[]\n",
    "confusion=[]\n",
    "class_out=[]\n",
    "for i in range(10): \n",
    "    model=DecisionTreeClassifier()\n",
    "    x=total_wine.drop(columns='wine_type')\n",
    "    y=total_wine['wine_type']\n",
    "    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "    scale=MinMaxScaler()\n",
    "    x_train_n= scale.fit_transform(x_train)\n",
    "    x_train_n= pd.DataFrame(x_train_n, columns=x_train.columns)\n",
    "    x_test_n= scale.fit_transform(x_test)\n",
    "    x_test_n= pd.DataFrame(x_test_n, columns=x_test.columns)\n",
    "    model.fit(x_train_n, y_train)\n",
    "    pred=model.predict(x_test_n)\n",
    "    scor=accuracy_score(pred, y_test)\n",
    "    score.append(scor)\n",
    "\n",
    "    con=confusion_matrix(y_test, pred)\n",
    "    confusion.append(con)\n",
    "    class_p= classification_report(y_test,pred)\n",
    "    class_out.append(class_p)\n",
    "    cohe=cohen_kappa_score(y_test, pred)\n",
    "    cohen.append(cohe)\n",
    "    i +=1\n",
    "print('score :\\n', np.mean(score),'\\ncohen: \\n',np.mean(cohen),'\\nconfusion \\n',confusion, 'classification: \\n',class_out)\n",
    "res=permutation_importance(model, x_train_n,y_train, scoring='f1')\n",
    "importance=res.importances_mean\n",
    "for i, v in enumerate(importance):\n",
    "    print('Feature : %5d , importance %0.5f ' %(i,v))\n",
    "plt.bar([x for x in range(len(importance))], importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score :\n",
      " 0.9854871794871796 \n",
      "cohen: \n",
      " 0.9612754376336413 \n",
      "confusion \n",
      " [array([[1455,   21],\n",
      "       [  14,  460]]), array([[1444,   13],\n",
      "       [   8,  485]]), array([[1437,   10],\n",
      "       [  15,  488]]), array([[1473,   17],\n",
      "       [   9,  451]]), array([[1465,   16],\n",
      "       [   9,  460]]), array([[1443,   15],\n",
      "       [  20,  472]]), array([[1461,   15],\n",
      "       [  10,  464]]), array([[1430,   20],\n",
      "       [  11,  489]]), array([[1436,   17],\n",
      "       [  12,  485]]), array([[1442,   17],\n",
      "       [  14,  477]])] classification: \n",
      " ['              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1476\\n         1.0       0.96      0.97      0.96       474\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.97      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1457\\n         1.0       0.97      0.98      0.98       493\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.99      0.99      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1447\\n         1.0       0.98      0.97      0.98       503\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1490\\n         1.0       0.96      0.98      0.97       460\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1481\\n         1.0       0.97      0.98      0.97       469\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.99      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1458\\n         1.0       0.97      0.96      0.96       492\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.97      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1476\\n         1.0       0.97      0.98      0.97       474\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1450\\n         1.0       0.96      0.98      0.97       500\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1453\\n         1.0       0.97      0.98      0.97       497\\n\\n    accuracy                           0.99      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.99      0.99      0.99      1950\\n', '              precision    recall  f1-score   support\\n\\n         0.0       0.99      0.99      0.99      1459\\n         1.0       0.97      0.97      0.97       491\\n\\n    accuracy                           0.98      1950\\n   macro avg       0.98      0.98      0.98      1950\\nweighted avg       0.98      0.98      0.98      1950\\n']\n",
      "Feature :     0 , importance 0.05562 \n",
      "Feature :     1 , importance 0.07335 \n",
      "Feature :     2 , importance 0.12562 \n",
      "Feature :     3 , importance 0.31916 \n",
      "Feature :     4 , importance 0.11576 \n",
      "Feature :     5 , importance 0.03379 \n",
      "Feature :     6 , importance 0.02880 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Although decision tree has own feature_importance, but permutation can also be used for it (results of both show almost similar outcomes)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cohen=[]\n",
    "score=[]\n",
    "confusion=[]\n",
    "class_out=[]\n",
    "for i in range(10): \n",
    "    model=DecisionTreeClassifier()\n",
    "    x=total_wine.drop(columns=['fixed_acidity','citric_acid','free_sulfur_dioxide','pH','quality','wine_type'])\n",
    "    y=total_wine['wine_type']\n",
    "    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "    scale=MinMaxScaler()\n",
    "    x_train_n= scale.fit_transform(x_train)\n",
    "    x_train_n= pd.DataFrame(x_train_n, columns=x_train.columns)\n",
    "    x_test_n= scale.fit_transform(x_test)\n",
    "    x_test_n= pd.DataFrame(x_test_n, columns=x_test.columns)\n",
    "    model.fit(x_train_n, y_train)\n",
    "    pred=model.predict(x_test_n)\n",
    "    scor=accuracy_score(pred, y_test)\n",
    "    score.append(scor)\n",
    "\n",
    "    con=confusion_matrix(y_test, pred)\n",
    "    confusion.append(con)\n",
    "    class_p= classification_report(y_test,pred)\n",
    "    class_out.append(class_p)\n",
    "    cohe=cohen_kappa_score(y_test, pred)\n",
    "    cohen.append(cohe)\n",
    "    i +=1\n",
    "print('score :\\n', np.mean(score),'\\ncohen: \\n',np.mean(cohen),'\\nconfusion \\n',confusion, 'classification: \\n',class_out)\n",
    "res=permutation_importance(model, x_train_n,y_train, scoring='f1')\n",
    "importance=res.importances_mean\n",
    "for i, v in enumerate(importance):\n",
    "    print('Feature : %5d , importance %0.5f ' %(i,v))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nm/btrww2_94pncl34mb0yt49j80000gn/T/ipykernel_91951/3271794618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcohen_kappa_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "cohen=[]\n",
    "score=[]\n",
    "confusion=[]\n",
    "class_out=[]\n",
    "for i in range(10): \n",
    "    model=XGBClassifier()\n",
    "    x=total_wine.drop(columns='wine_type')\n",
    "    y=total_wine['wine_type']\n",
    "    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "    scale=MinMaxScaler()\n",
    "    x_train_n= scale.fit_transform(x_train)\n",
    "    x_train_n= pd.DataFrame(x_train_n, columns=x_train.columns)\n",
    "    x_test_n= scale.fit_transform(x_test)\n",
    "    x_test_n= pd.DataFrame(x_test_n, columns=x_test.columns)\n",
    "    model.fit(x_train_n, y_train)\n",
    "    pred=model.predict(x_test_n)\n",
    "    scor=accuracy_score(pred, y_test)\n",
    "    score.append(scor)\n",
    "\n",
    "    con=confusion_matrix(y_test, pred)\n",
    "    confusion.append(con)\n",
    "    class_p= classification_report(y_test,pred)\n",
    "    class_out.append(class_p)\n",
    "    cohe=cohen_kappa_score(y_test, pred)\n",
    "    cohen.append(cohe)\n",
    "    i +=1\n",
    "print('score :\\n', np.mean(score),'\\ncohen: \\n',np.mean(cohen),'\\nconfusion \\n',confusion, 'classification: \\n',class_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marziehbaes/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>0.151911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalized</th>\n",
       "      <td>0.087706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized</th>\n",
       "      <td>0.087706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RMSE\n",
       "Original      0.151911\n",
       "Normalized    0.087706\n",
       "Standardized  0.087706"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check how normalisation, standardization affect the model results:\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model=LogisticRegression()\n",
    "x=total_wine.drop(columns='wine_type')\n",
    "y=total_wine['wine_type']\n",
    "x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "scale=StandardScaler()\n",
    "x_train_stand= scale.fit_transform(x_train)\n",
    "x_train_stand= pd.DataFrame(x_train_stand, columns=x_train.columns)\n",
    "x_test_stand= scale.fit_transform(x_test)\n",
    "x_test_stand= pd.DataFrame(x_test_stand, columns=x_test.columns)\n",
    "scale=MinMaxScaler()\n",
    "x_train_norm= scale.fit_transform(x_train)\n",
    "x_train_norm= pd.DataFrame(x_train_norm, columns=x_train.columns)\n",
    "x_test_norm= scale.fit_transform(x_test)\n",
    "x_test_norm= pd.DataFrame(x_test_norm, columns=x_test.columns)\n",
    "rmse = []\n",
    "\n",
    "# raw, normalized and standardized training and testing data\n",
    "trainX = [x_train, x_train_norm, x_train_stand]\n",
    "testX = [x_test, x_test_norm, x_test_stand]\n",
    "\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "    \n",
    "    # fit\n",
    "    model.fit(trainX[i],y_train)\n",
    "    # predict\n",
    "    pred = model.predict(testX[i])\n",
    "    # RMSE\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "\n",
    "# visualizing the result\n",
    "df_knn = pd.DataFrame({'RMSE':rmse},index=['Original','Normalized','Standardized'])\n",
    "df_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>0.071611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalized</th>\n",
       "      <td>0.071611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized</th>\n",
       "      <td>0.078446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RMSE\n",
       "Original      0.071611\n",
       "Normalized    0.071611\n",
       "Standardized  0.078446"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check how normalisation, standardization affect the model results:\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model=LinearDiscriminantAnalysis()\n",
    "x=total_wine.drop(columns='wine_type')\n",
    "y=total_wine['wine_type']\n",
    "x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "scale=StandardScaler()\n",
    "x_train_stand= scale.fit_transform(x_train)\n",
    "x_train_stand= pd.DataFrame(x_train_stand, columns=x_train.columns)\n",
    "x_test_stand= scale.fit_transform(x_test)\n",
    "x_test_stand= pd.DataFrame(x_test_stand, columns=x_test.columns)\n",
    "scale=MinMaxScaler()\n",
    "x_train_norm= scale.fit_transform(x_train)\n",
    "x_train_norm= pd.DataFrame(x_train_norm, columns=x_train.columns)\n",
    "x_test_norm= scale.fit_transform(x_test)\n",
    "x_test_norm= pd.DataFrame(x_test_norm, columns=x_test.columns)\n",
    "rmse = []\n",
    "\n",
    "# raw, normalized and standardized training and testing data\n",
    "trainX = [x_train, x_train_norm, x_train_stand]\n",
    "testX = [x_test, x_test_norm, x_test_stand]\n",
    "\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "    \n",
    "    # fit\n",
    "    model.fit(trainX[i],y_train)\n",
    "    # predict\n",
    "    pred = model.predict(testX[i])\n",
    "    # RMSE\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "\n",
    "# visualizing the result\n",
    "df_knn = pd.DataFrame({'RMSE':rmse},index=['Original','Normalized','Standardized'])\n",
    "df_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>0.261161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalized</th>\n",
       "      <td>0.045291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized</th>\n",
       "      <td>0.050637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RMSE\n",
       "Original      0.261161\n",
       "Normalized    0.045291\n",
       "Standardized  0.050637"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check how normalisation, standardization affect the model results:\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model=SVC()\n",
    "x=total_wine.drop(columns='wine_type')\n",
    "y=total_wine['wine_type']\n",
    "x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3)\n",
    "scale=StandardScaler()\n",
    "x_train_stand= scale.fit_transform(x_train)\n",
    "x_train_stand= pd.DataFrame(x_train_stand, columns=x_train.columns)\n",
    "x_test_stand= scale.fit_transform(x_test)\n",
    "x_test_stand= pd.DataFrame(x_test_stand, columns=x_test.columns)\n",
    "scale=MinMaxScaler()\n",
    "x_train_norm= scale.fit_transform(x_train)\n",
    "x_train_norm= pd.DataFrame(x_train_norm, columns=x_train.columns)\n",
    "x_test_norm= scale.fit_transform(x_test)\n",
    "x_test_norm= pd.DataFrame(x_test_norm, columns=x_test.columns)\n",
    "rmse = []\n",
    "\n",
    "# raw, normalized and standardized training and testing data\n",
    "trainX = [x_train, x_train_norm, x_train_stand]\n",
    "testX = [x_test, x_test_norm, x_test_stand]\n",
    "\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "    \n",
    "    # fit\n",
    "    model.fit(trainX[i],y_train)\n",
    "    # predict\n",
    "    pred = model.predict(testX[i])\n",
    "    # RMSE\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "\n",
    "# visualizing the result\n",
    "df_knn = pd.DataFrame({'RMSE':rmse},index=['Original','Normalized','Standardized'])\n",
    "df_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2615250151.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/nm/btrww2_94pncl34mb0yt49j80000gn/T/ipykernel_91951/2615250151.py\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3,,random_state=42, shuffle=True)\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# to check how normalisation, standardization affect the model results:\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "x=total_wine.drop(columns='wine_type')\n",
    "y=total_wine['wine_type']\n",
    "x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3,,random_state=42, shuffle=True)\n",
    "scale=StandardScaler()\n",
    "x_train_stand= scale.fit_transform(x_train)\n",
    "x_train_stand= pd.DataFrame(x_train_stand, columns=x_train.columns)\n",
    "x_test_stand= scale.fit_transform(x_test)\n",
    "x_test_stand= pd.DataFrame(x_test_stand, columns=x_test.columns)\n",
    "scale=MinMaxScaler()\n",
    "x_train_norm= scale.fit_transform(x_train)\n",
    "x_train_norm= pd.DataFrame(x_train_norm, columns=x_train.columns)\n",
    "x_test_norm= scale.fit_transform(x_test)\n",
    "x_test_norm= pd.DataFrame(x_test_norm, columns=x_test.columns)\n",
    "rmse = []\n",
    "\n",
    "# raw, normalized and standardized training and testing data\n",
    "trainX = [x_train, x_train_norm, x_train_stand]\n",
    "testX = [x_test, x_test_norm, x_test_stand]\n",
    "\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "    \n",
    "    # fit\n",
    "    model.fit(trainX[i],y_train)\n",
    "    # predict\n",
    "    pred = model.predict(testX[i])\n",
    "    # RMSE\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "\n",
    "# visualizing the result\n",
    "df_knn = pd.DataFrame({'RMSE':rmse},index=['Original','Normalized','Standardized'])\n",
    "df_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>0.121950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalized</th>\n",
       "      <td>0.248069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standardized</th>\n",
       "      <td>0.119829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RMSE\n",
       "Original      0.121950\n",
       "Normalized    0.248069\n",
       "Standardized  0.119829"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check how normalisation, standardization affect the model results:\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model=DecisionTreeClassifier()\n",
    "x=total_wine.drop(columns='wine_type')\n",
    "y=total_wine['wine_type']\n",
    "x_train,x_test,y_train, y_test=train_test_split(x,y, test_size=0.3,random_state=42, shuffle=True)\n",
    "scale=StandardScaler()\n",
    "x_train_stand= scale.fit_transform(x_train)\n",
    "x_train_stand= pd.DataFrame(x_train_stand, columns=x_train.columns)\n",
    "x_test_stand= scale.fit_transform(x_test)\n",
    "x_test_stand= pd.DataFrame(x_test_stand, columns=x_test.columns)\n",
    "scale=MinMaxScaler()\n",
    "x_train_norm= scale.fit_transform(x_train)\n",
    "x_train_norm= pd.DataFrame(x_train_norm, columns=x_train.columns)\n",
    "x_test_norm= scale.fit_transform(x_test)\n",
    "x_test_norm= pd.DataFrame(x_test_norm, columns=x_test.columns)\n",
    "rmse = []\n",
    "\n",
    "# raw, normalized and standardized training and testing data\n",
    "trainX = [x_train, x_train_norm, x_train_stand]\n",
    "testX = [x_test, x_test_norm, x_test_stand]\n",
    "\n",
    "# model fitting and measuring RMSE\n",
    "for i in range(len(trainX)):\n",
    "    \n",
    "    # fit\n",
    "    model.fit(trainX[i],y_train)\n",
    "    # predict\n",
    "    pred = model.predict(testX[i])\n",
    "    # RMSE\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "\n",
    "# visualizing the result\n",
    "df_knn = pd.DataFrame({'RMSE':rmse},index=['Original','Normalized','Standardized'])\n",
    "df_knn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2918784d2acf282f2c1eeb3293c1f68c9e526abdf8983671e7e8ea84935e28a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
